% Chapter Template

\chapter{Background Information \& Related Work}\label{chap:background_n_related}

% ROUGH DRAFT
\textcite{gordeev_unsupervised_2018} uses unsupervised cross-lingual embeddings to match cross-lingual product classifications.
Working on taxonomy matching, they use out of domain pre-trained embeddings due to small size of their corpora and investigate methods using untranslated and translated text.

\textcite{irvine_comprehensive_2017} used as a guideline on best practices.

\textcite{banerjee_adapted_2002} developed on lesk algorithm and included WordNet.


\textcite{khodak_automated_2017} used word embeddings and WordNet.

\textcite{metzler_similarity_2007} talked about short text retrieval and lexical matching. They reported that lexical matching is good for finding semantically identical matches.A

\textcite{sagot_building_2008} built a French wordnet.

\textcite{balikas_cross-lingual_2018} suggested using optimal transport for cross-lingual document retrieval.

\textcite{kusner_word_2015} is Word Mover's Distance.

\textcite{jonker_shortest_1987} lapjv paper.

\textcite{arora_simple_2016} simple but tough-to-beat baseline for sentence embeddings.
